{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc4a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from random import sample, random, seed\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4b78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed = 42\n",
    "torch.manual_seed(set_seed)\n",
    "torch.cuda.manual_seed(set_seed)\n",
    "torch.cuda.manual_seed_all(set_seed)\n",
    "np.random.seed(set_seed)\n",
    "seed(set_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99fe64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 50\n",
    "MARGIN = 1\n",
    "BATCH_SIZE = 512\n",
    "TOP_K = 100\n",
    "CORRUPTED_NUM = 100\n",
    "NORM = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b96fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/darpa_datasets/data/all_event_5d_4.4_transE.pkl','rb') as f:\n",
    "#     ls = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13887f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = []\n",
    "# for i,(subject,relation,object_) in tqdm(enumerate(ls),total=len(ls)): \n",
    "#     if subject['n_attrbiute']['cmdline'] != 'None' and relation['relation'] != 'None':\n",
    "#         for key,value in object_['n_attrbiute'].items(): \n",
    "#             if value == 'None':\n",
    "#                 break\n",
    "#         else:\n",
    "#             '''\n",
    "#             object_'s key should not be in ['type','pid','localAddress', 'localPort', 'ipProtocol'], 英仁說的\n",
    "#             values of 'remoteAddress' and 'remotePort' should be concatenated, 英仁說的\n",
    "#             '''\n",
    "#             filtered_object = list(filter(lambda x: x[0] not in ['type','pid','localAddress', 'localPort', 'ipProtocol'],object_['n_attrbiute'].items()))\n",
    "#             object_data = ':'.join([str(y) for x,y in filtered_object])\n",
    "#             temp.append([subject['n_attrbiute']['cmdline'], relation['relation'], object_data, relation['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee98d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(temp,columns=['Subject','relation','Object','malicious_or_benign'])\n",
    "# train_df, valid_df = train_test_split(df, test_size=0.2,random_state=42,shuffle=True)\n",
    "# valid_df, test_df = train_test_split(valid_df, test_size=0.5,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c820239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('./data/darpa_datasets/train_df.csv',index=False)\n",
    "# valid_df.to_csv('./data/darpa_datasets/valid_df.csv',index=False)\n",
    "# test_df.to_csv('./data/darpa_datasets/test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31eb6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/darpa_datasets/train_df.csv')\n",
    "valid_df = pd.read_csv('./data/darpa_datasets/valid_df.csv')\n",
    "test_df = pd.read_csv('./data/darpa_datasets/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ffc4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(list(set(train_df['Subject']) | set(train_df['Object'])))\n",
    "subj_obj_dic = dict(zip(data,range(len(data))))\n",
    "data = sorted(list(set(train_df['relation'])))\n",
    "relation_dic = dict(zip(data,range(len(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05244ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63285\n"
     ]
    }
   ],
   "source": [
    "print(len(subj_obj_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff845c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['Subject'] = train_df['Subject'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "train_df['Object'] = train_df['Object'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "train_df['relation'] = train_df['relation'].map(lambda x: relation_dic.get(x,len(relation_dic)))\n",
    "\n",
    "valid_df['Subject'] = valid_df['Subject'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "valid_df['Object'] = valid_df['Object'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "valid_df['relation'] = valid_df['relation'].map(lambda x: relation_dic.get(x,len(relation_dic)))\n",
    "\n",
    "test_df['Subject'] = test_df['Subject'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "test_df['Object'] = test_df['Object'].map(lambda x: subj_obj_dic.get(x,len(subj_obj_dic)))\n",
    "test_df['relation'] = test_df['relation'].map(lambda x: relation_dic.get(x,len(relation_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4794fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE_Model(nn.Module):\n",
    "    def __init__(self,entity_num:int,relation_num:int,embedding_dim:int,NORM:int=1):\n",
    "        super().__init__()\n",
    "        self.NORM = NORM\n",
    "        self.entity_num = entity_num\n",
    "        self.relation_num = relation_num\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.entity_embedding = self.generate_embedding(self.entity_num)\n",
    "        self.relation_embedding = self.generate_embedding(self.relation_num)\n",
    "        self.relation_embedding = self.normalize_embedding(self.relation_embedding)\n",
    "    \n",
    "    def generate_embedding(self,num):\n",
    "        emb = nn.Embedding(num_embeddings=num+1,embedding_dim=self.embedding_dim,padding_idx=num)\n",
    "        emb.weight.data.uniform_(-6/(self.embedding_dim**0.5),6/(self.embedding_dim**0.5))\n",
    "        return emb\n",
    "    \n",
    "    def normalize_embedding(self,emb):\n",
    "        emb.weight.data /= emb.weight.data.norm(p=self.NORM,dim=1,keepdim=True)\n",
    "        return emb\n",
    "    \n",
    "    def forward(self,subject,relation,object_):\n",
    "        x = self.entity_embedding(subject)\n",
    "        x += self.relation_embedding(relation)\n",
    "        x -= self.entity_embedding(object_)\n",
    "        return x.norm(p=self.NORM,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b49474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.data = [tuple(i) for i in df.values]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class Generate_Corrupted_Triple():\n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        self.obj = set(df['Object'])\n",
    "        self.subj = set(df['Subject'])\n",
    "        self.s_2_o_dic, self.o_2_s_dic = self.generate_dic(df)\n",
    "    def generate_dic(self,df):\n",
    "        s_2_o_dic = defaultdict(set)\n",
    "        o_2_s_dic = defaultdict(set)\n",
    "        for s,r,o,b_or_m in df.values:\n",
    "            s_2_o_dic[s].add(o)\n",
    "            o_2_s_dic[o].add(s)\n",
    "        return s_2_o_dic,o_2_s_dic\n",
    "    def __call__(self,subject,relation,object_):\n",
    "        new_subject = torch.tensor([sample(self.subj - self.o_2_s_dic[obj],k=1)[0] for obj in object_.cpu().numpy()])\n",
    "        new_object = torch.tensor([sample(self.obj - self.s_2_o_dic[subj],k=1)[0] for subj in subject.cpu().numpy()])\n",
    "        return [new_subject,relation,object_],[subject,relation,new_object]\n",
    "    \n",
    "class Generate_Corrupted_Triple():\n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        self.obj_dic, self.subj_dic = self.generate_dic(df)\n",
    "    def generate_dic(self,df):\n",
    "        obj = set(df['Object'])\n",
    "        subj = set(df['Subject'])\n",
    "        subj_dic = defaultdict(set)\n",
    "        obj_dic = defaultdict(set)\n",
    "        s_2_o_dic = defaultdict(set)\n",
    "        o_2_s_dic = defaultdict(set)\n",
    "        for s,r,o,b_or_m in df.values:\n",
    "            s_2_o_dic[s].add(o)\n",
    "            o_2_s_dic[o].add(s)\n",
    "        for key,value in o_2_s_dic.items():\n",
    "            obj_dic[key] = subj - value\n",
    "        for key,value in s_2_o_dic.items():\n",
    "            subj_dic[key] = obj - value\n",
    "        return obj_dic,subj_dic\n",
    "    def __call__(self,subject,relation,object_):\n",
    "        new_subject = torch.tensor([sample(self.obj_dic[obj], k=1)[0] for obj in object_.cpu().numpy()])\n",
    "        new_object = torch.tensor([sample(self.subj_dic[subj], k=1)[0] for subj in subject.cpu().numpy()])\n",
    "        return [new_subject,relation,object_],[subject,relation,new_object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fea4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def To_Device(batch,device):\n",
    "    return [b.to(device) for b in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d15922",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE_Model(\n",
    "    entity_num=len(set(train_df['Subject']) | set(train_df['Object'])),\n",
    "    relation_num=len(set(train_df['relation'])),\n",
    "    embedding_dim=DIM,NORM=NORM\n",
    ").to(device)\n",
    "optim_fn = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.MarginRankingLoss(margin=MARGIN).to(device)\n",
    "GCT = Generate_Corrupted_Triple(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bebb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df, test_size=0.2)\n",
    "train_dataset = Custom_Dataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_dataset = Custom_Dataset(valid_df)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=16,shuffle=False)\n",
    "test_dataset = Custom_Dataset(test_df)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e688264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,loss_fn,optim_fn,device):\n",
    "    losses = []\n",
    "    bar = tqdm(enumerate(train_dataloader),total=len(train_dataloader))\n",
    "    target = torch.tensor([-1], dtype=torch.long, device=device)\n",
    "    for idx,batch in bar: \n",
    "        model.entity_embedding = model.normalize_embedding(model.entity_embedding)\n",
    "        corrupted_batch_1,corrupted_batch_2 = GCT(*batch[:3])\n",
    "        loss = 0.5*loss_fn(\n",
    "            model(*To_Device(batch[:3],device)),model(*To_Device(corrupted_batch_1,device)),target\n",
    "        ) + 0.5*loss_fn(\n",
    "            model(*To_Device(batch[:3],device)),model(*To_Device(corrupted_batch_2,device)),target\n",
    "        )\n",
    "        # if random() > 0.5:\n",
    "        #     loss = loss_fn(\n",
    "        #         model(*To_Device(batch,device)),model(*To_Device(corrupted_batch_1,device)),target\n",
    "        #     )\n",
    "        # else:\n",
    "        #     loss = loss_fn(\n",
    "        #         model(*To_Device(batch,device)),model(*To_Device(corrupted_batch_2,device)),target\n",
    "        #     )\n",
    "        optim_fn.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_fn.step()\n",
    "        losses.append(loss.item())\n",
    "        bar.set_description(f'loss: {np.mean(losses):8.7f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5bd33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model,dataloader,device,TOP_K):\n",
    "    top_k = []\n",
    "    bar = tqdm(dataloader)\n",
    "    for batch in bar:\n",
    "        subject,relation,object_ = To_Device(batch[:3],device)\n",
    "        temp = model.entity_embedding(subject)\n",
    "        temp += model.relation_embedding(relation)\n",
    "        # temp -= model.entity_embedding(object_)\n",
    "\n",
    "        shape = temp.shape\n",
    "        temp = temp.unsqueeze(1)\n",
    "        temp = temp.expand(shape[0],len(model.entity_embedding.weight),shape[1])\n",
    "\n",
    "        entity_weight = model.entity_embedding.weight.unsqueeze(0)\n",
    "        entity_weight = entity_weight.expand(shape[0],len(model.entity_embedding.weight),shape[1]).to(device)\n",
    "\n",
    "        values,indices = torch.topk((temp - entity_weight).norm(p=NORM,dim=2),k=TOP_K,largest=False)\n",
    "        top_k.append(torch.eq(indices , batch[2].unsqueeze(1).to(device)).float().sum().item()/len(batch[0]))\n",
    "        bar.set_description(f'top_{TOP_K}: {np.mean(top_k):8.7f}')\n",
    "    return np.mean(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5742e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0607305: 100%|██████████| 10444/10444 [1:13:24<00:00,  2.37it/s]\n",
      "top_100: 0.7355063: 100%|██████████| 41774/41774 [03:07<00:00, 222.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0252982: 100%|██████████| 10444/10444 [1:14:08<00:00,  2.35it/s]\n",
      "top_100: 0.7135489: 100%|██████████| 41774/41774 [03:04<00:00, 226.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0237640:   1%|          | 112/10444 [00:52<1:21:06,  2.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-46f8f631d86e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTOP_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'./models/darpa/epoch_{i}_top_{TOP_K}_{top_k}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-64577290b7e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, loss_fn, optim_fn, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcorrupted_batch_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrupted_batch_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         loss = 0.5*loss_fn(\n\u001b[1;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTo_Device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mTo_Device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrupted_batch_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-daed47924537>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, subject, relation, object_)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mnew_subject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubj_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_subject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_object\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-daed47924537>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mnew_subject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubj_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_subject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_object\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Population must be a sequence or set.  For dicts, use list(d).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = train(model,train_dataloader,loss_fn,optim_fn,device)\n",
    "    top_k = valid(model,valid_dataloader,device,TOP_K)\n",
    "    torch.save(model,f'./models/darpa/epoch_{i}_top_{TOP_K}_{top_k}.pt')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
